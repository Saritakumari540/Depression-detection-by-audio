{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeallJ+7MnwYpT5hKitiXC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saritakumari540/Depression-detection-by-audio/blob/main/DepressionDetectionByAudio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downgrading versions for our project usecase"
      ],
      "metadata": {
        "id": "xhgxzu6W0Q01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y\n",
        "!apt-get install python3.8 python3.8-distutils\n",
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "!update-alternatives --config python3\n",
        "!apt-get install python3-pip\n",
        "!python3 -m pip install --upgrade pip --user"
      ],
      "metadata": {
        "id": "8dQoLL-90Qce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install and import dependencies"
      ],
      "metadata": {
        "id": "YTa_OLs-wIhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 tensorflow-io matplotlib"
      ],
      "metadata": {
        "id": "STRyVSHd04Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://zenodo.org/records/1188976/files/Audio_Speech_Actors_01-24.zip?download=1"
      ],
      "metadata": {
        "id": "t0Q-ViZcwCDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data/input\n",
        "!mkdir -p data/working/Depression\n",
        "!mkdir -p data/working/NonDepression"
      ],
      "metadata": {
        "id": "y5Odmf4Zw5HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Audio_Speech_Actors_01-24.zip?download=1 -d ./data/input"
      ],
      "metadata": {
        "id": "7hwPcCLDzSjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjqRbvQgzu7f",
        "outputId": "cf8ddbfb-4393-43c5-8427-3a39b785759d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-io in /usr/local/lib/python3.8/dist-packages (0.34.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.34.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-io) (0.34.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import shutil"
      ],
      "metadata": {
        "id": "GvvaFYQdz16v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "tsnS4aRMyPst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_src_directory = \"data/input\"\n",
        "destination_directories = {\n",
        "    'Depression': 'data/working/Depression/',\n",
        "    'NonDepression': 'data/working/NonDepression/'\n",
        "}\n",
        "\n",
        "def copy_files_with_specific_number():\n",
        "    count = 0\n",
        "    for i in range(1, 25):\n",
        "        actor_folder = f\"Actor_{str(i).zfill(2)}\"\n",
        "        src_directory = os.path.join(base_src_directory, actor_folder)\n",
        "\n",
        "        for category, base_destination_directory in destination_directories.items():\n",
        "            destination_directory = os.path.join(base_destination_directory)\n",
        "\n",
        "            if not os.path.exists(destination_directory):\n",
        "                os.makedirs(destination_directory)\n",
        "\n",
        "            for filename in os.listdir(src_directory):\n",
        "                if '-' in filename:\n",
        "                    parts = filename.split('-')\n",
        "                    if len(parts) >= 3:\n",
        "                        number = parts[2][:2]\n",
        "                        if (category == 'Depression' and number in ['04', '05', '06', '07']) or \\\n",
        "                           (category == 'NonDepression' and number in ['01', '02', '03', '08']):\n",
        "                            source_path = os.path.join(src_directory, filename)\n",
        "                            destination_path = os.path.join(destination_directory, filename)\n",
        "                            shutil.copy(source_path, destination_path)\n",
        "                            count += 1\n",
        "    print(f\"Total files moved: {count}\")\n",
        "\n",
        "copy_files_with_specific_number()"
      ],
      "metadata": {
        "id": "Atpa9y7YxbZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "cgNIhiAl41F7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_header_and_size(wav_filename):\n",
        "    with wave.open(wav_filename, 'r') as fin:\n",
        "        header_fsize = (fin.getnframes() * fin.getnchannels() * fin.getsampwidth()) + 44\n",
        "    file_fsize = os.path.getsize(wav_filename)\n",
        "    return header_fsize != file_fsize\n"
      ],
      "metadata": {
        "id": "jwFOFrZnKkac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEPRESSION_FILE = os.path.join('data', 'working', 'Depression', '03-01-05-01-01-01-02.wav')\n",
        "NOT_DEPRESSION_FILE = os.path.join('data', 'working', 'NonDepression', '03-01-02-01-02-02-19.wav')"
      ],
      "metadata": {
        "id": "uI2bpF400EHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "def load_wav_16k_mono(filename):\n",
        "    try:\n",
        "        file_contents = tf.io.read_file(filename)\n",
        "        wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
        "        wav = tf.squeeze(wav, axis=-1)\n",
        "        sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "        wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "        return wav\n",
        "    except tf.errors.InvalidArgumentError as e:\n",
        "        # Print warning and skip this file if itâ€™s corrupt or invalid\n",
        "        print(f\"Warning: Skipping file {filename} due to error: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "9IPhzAfW6h75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wave = load_wav_16k_mono(DEPRESSION_FILE)\n",
        "nwave = load_wav_16k_mono(NOT_DEPRESSION_FILE)"
      ],
      "metadata": {
        "id": "2ZFBVwdo6tFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(wave)\n",
        "plt.plot(nwave)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5SGeDwgf9dI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average length of Audio"
      ],
      "metadata": {
        "id": "_wcuNUAWG6GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = []\n",
        "for file in os.listdir(os.path.join('data', 'working', 'Depression')):\n",
        "    tensor_wave = load_wav_16k_mono(os.path.join('data', 'working', 'Depression', file))\n",
        "    if tensor_wave is not None:\n",
        "        lengths.append(len(tensor_wave))\n",
        "    else:\n",
        "        print(f\"Skipping file {file} due to loading error.\")\n",
        "        os.remove(f\"data/working/Depression/{file}\")\n",
        "for file in os.listdir(os.path.join('data', 'working', 'NonDepression')):\n",
        "    tensor_wave = load_wav_16k_mono(os.path.join('data', 'working', 'NonDepression', file))\n",
        "    if tensor_wave is not None:\n",
        "        lengths.append(len(tensor_wave))\n",
        "    else:\n",
        "        print(f\"Skipping file {file} due to loading error.\")\n",
        "        os.remove(f\"data/working/NonDepression/{file}\")"
      ],
      "metadata": {
        "id": "oRh50t7iGwLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.reduce_mean(lengths)"
      ],
      "metadata": {
        "id": "CKpHOy2gHrUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.reduce_min(lengths)"
      ],
      "metadata": {
        "id": "ByMkiJrTIDC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.reduce_max(lengths)"
      ],
      "metadata": {
        "id": "18RqJMzaIEde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow dataset pipeline"
      ],
      "metadata": {
        "id": "N5SDYf2gGbLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "POS = os.path.join('data', 'working', 'Depression')\n",
        "NEG = os.path.join('data', 'working', 'NonDepression')"
      ],
      "metadata": {
        "id": "sXXBmUnjFlzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos = tf.data.Dataset.list_files(POS+'/*.wav')\n",
        "neg = tf.data.Dataset.list_files(NEG+'/*.wav')"
      ],
      "metadata": {
        "id": "ca251c78GplU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
        "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
        "data = positives.concatenate(negatives)"
      ],
      "metadata": {
        "id": "0s_Xfh1gGsJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "eJU-umyXGuFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "9y7WrjgnIL9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_path, label):\n",
        "    wav = load_wav_16k_mono(file_path)\n",
        "    wav = wav[:48000]\n",
        "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
        "    wav = tf.concat([zero_padding, wav],0)\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram, label"
      ],
      "metadata": {
        "id": "Q73_CW1gIHMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "EtU2BYUaIQ3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectrogram, label = preprocess(filepath, label)"
      ],
      "metadata": {
        "id": "zL318cBLITLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,20))\n",
        "plt.imshow(tf.transpose(spectrogram)[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qKTQWzUgIU4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train test partitioning"
      ],
      "metadata": {
        "id": "G3XlvdklIejp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.map(preprocess)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=1000)\n",
        "data = data.batch(16)\n",
        "data = data.prefetch(8)\n"
      ],
      "metadata": {
        "id": "aQayCANyIWcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = data.take(36)\n",
        "test = data.skip(36).take(15)"
      ],
      "metadata": {
        "id": "4GGa-kRDIilG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples, labels = train.as_numpy_iterator().next()\n",
        "samples.shape"
      ],
      "metadata": {
        "id": "RrMnik4-IkmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Deep learning model"
      ],
      "metadata": {
        "id": "SPLgXc6hbWjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
      ],
      "metadata": {
        "id": "sZuuWK5bIpDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491,257,1)))\n",
        "model.add(Conv2D(16, (3,3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "vPvkkVN9bfif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
      ],
      "metadata": {
        "id": "qlU3JNUwbhRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train, epochs=4, validation_data=test)"
      ],
      "metadata": {
        "id": "pIpD7-scbxk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(hist.history['loss'], 'r')\n",
        "plt.plot(hist.history['val_loss'], 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ERiCQuTjFj_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Precision')\n",
        "plt.plot(hist.history['precision'], 'r')\n",
        "plt.plot(hist.history['val_precision'], 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lg_ZPmqpFnk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Recall')\n",
        "plt.plot(hist.history['recall'], 'r')\n",
        "plt.plot(hist.history['val_recall'], 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KJQITAJUFo_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making prediction"
      ],
      "metadata": {
        "id": "hgJRZiFeFt0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = test.as_numpy_iterator().next()\n",
        "yhat = model.predict(X_test)"
      ],
      "metadata": {
        "id": "dzdk2QfmFvXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
      ],
      "metadata": {
        "id": "WCH9AwRHFy6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1xe5KjC5F2BA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}